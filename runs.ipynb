{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Faster RCNN",
   "id": "56fc9dc270cf3a92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/10 23:19:40 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.11.9 (main, Apr 17 2024, 00:00:00) [GCC 13.2.1 20240316 (Red Hat 13.2.1-7)]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 1907556048\r\n",
      "    GPU 0: NVIDIA GeForce RTX 3070\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.131\r\n",
      "    GCC: gcc (GCC) 13.2.1 20240316 (Red Hat 13.2.1-7)\r\n",
      "    PyTorch: 2.1.0+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 8.9.2\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.16.0+cu121\r\n",
      "    OpenCV: 4.9.0\r\n",
      "    MMEngine: 0.10.4\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 1907556048\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "05/10 23:19:40 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\r\n",
      "backend_args = None\r\n",
      "data_root = 'data/coco/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\r\n",
      "    logger=dict(interval=50, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(type='DetVisualizationHook'))\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "launcher = 'none'\r\n",
      "load_from = 'checkpoints/faster_rcnn_x101_64x4d_fpn_mstrain_3x.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        base_width=4,\r\n",
      "        depth=101,\r\n",
      "        frozen_stages=1,\r\n",
      "        groups=64,\r\n",
      "        init_cfg=dict(\r\n",
      "            checkpoint='open-mmlab://resnext101_64x4d', type='Pretrained'),\r\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\r\n",
      "        norm_eval=True,\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(\r\n",
      "            0,\r\n",
      "            1,\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "        ),\r\n",
      "        style='pytorch',\r\n",
      "        type='ResNeXt'),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        bgr_to_rgb=True,\r\n",
      "        mean=[\r\n",
      "            123.675,\r\n",
      "            116.28,\r\n",
      "            103.53,\r\n",
      "        ],\r\n",
      "        pad_size_divisor=32,\r\n",
      "        std=[\r\n",
      "            58.395,\r\n",
      "            57.12,\r\n",
      "            57.375,\r\n",
      "        ],\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        in_channels=[\r\n",
      "            256,\r\n",
      "            512,\r\n",
      "            1024,\r\n",
      "            2048,\r\n",
      "        ],\r\n",
      "        num_outs=5,\r\n",
      "        out_channels=256,\r\n",
      "        type='FPN'),\r\n",
      "    roi_head=dict(\r\n",
      "        bbox_head=dict(\r\n",
      "            bbox_coder=dict(\r\n",
      "                target_means=[\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                ],\r\n",
      "                target_stds=[\r\n",
      "                    0.1,\r\n",
      "                    0.1,\r\n",
      "                    0.2,\r\n",
      "                    0.2,\r\n",
      "                ],\r\n",
      "                type='DeltaXYWHBBoxCoder'),\r\n",
      "            fc_out_channels=1024,\r\n",
      "            in_channels=256,\r\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "            loss_cls=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\r\n",
      "            num_classes=80,\r\n",
      "            reg_class_agnostic=False,\r\n",
      "            roi_feat_size=7,\r\n",
      "            type='Shared2FCBBoxHead'),\r\n",
      "        bbox_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        type='StandardRoIHead'),\r\n",
      "    rpn_head=dict(\r\n",
      "        anchor_generator=dict(\r\n",
      "            ratios=[\r\n",
      "                0.5,\r\n",
      "                1.0,\r\n",
      "                2.0,\r\n",
      "            ],\r\n",
      "            scales=[\r\n",
      "                8,\r\n",
      "            ],\r\n",
      "            strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "                64,\r\n",
      "            ],\r\n",
      "            type='AnchorGenerator'),\r\n",
      "        bbox_coder=dict(\r\n",
      "            target_means=[\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "            ],\r\n",
      "            target_stds=[\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "            ],\r\n",
      "            type='DeltaXYWHBBoxCoder'),\r\n",
      "        feat_channels=256,\r\n",
      "        in_channels=256,\r\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\r\n",
      "        type='RPNHead'),\r\n",
      "    test_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            max_per_img=100,\r\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\r\n",
      "            score_thr=0.05),\r\n",
      "        rpn=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=1000)),\r\n",
      "    train_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=False,\r\n",
      "                min_pos_iou=0.5,\r\n",
      "                neg_iou_thr=0.5,\r\n",
      "                pos_iou_thr=0.5,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=True,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=512,\r\n",
      "                pos_fraction=0.25,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn=dict(\r\n",
      "            allowed_border=-1,\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.3,\r\n",
      "                neg_iou_thr=0.3,\r\n",
      "                pos_iou_thr=0.7,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=False,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=256,\r\n",
      "                pos_fraction=0.5,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn_proposal=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=2000)),\r\n",
      "    type='FasterRCNN')\r\n",
      "optim_wrapper = dict(\r\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0001),\r\n",
      "    type='OptimWrapper')\r\n",
      "param_scheduler = [\r\n",
      "    dict(\r\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\r\n",
      "    dict(\r\n",
      "        begin=0,\r\n",
      "        by_epoch=True,\r\n",
      "        end=12,\r\n",
      "        gamma=0.1,\r\n",
      "        milestones=[\r\n",
      "            9,\r\n",
      "            11,\r\n",
      "        ],\r\n",
      "        type='MultiStepLR'),\r\n",
      "]\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        1333,\r\n",
      "        800,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=12, type='EpochBasedTrainLoop', val_interval=1)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\r\n",
      "    batch_size=2,\r\n",
      "    dataset=dict(\r\n",
      "        dataset=dict(\r\n",
      "            ann_file='annotations/instances_train2017.json',\r\n",
      "            backend_args=None,\r\n",
      "            data_prefix=dict(img='train2017/'),\r\n",
      "            data_root='data/coco/',\r\n",
      "            filter_cfg=dict(filter_empty_gt=True, min_size=32),\r\n",
      "            pipeline=[\r\n",
      "                dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "                dict(\r\n",
      "                    keep_ratio=True,\r\n",
      "                    scale=[\r\n",
      "                        (\r\n",
      "                            1333,\r\n",
      "                            640,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            1333,\r\n",
      "                            800,\r\n",
      "                        ),\r\n",
      "                    ],\r\n",
      "                    type='RandomResize'),\r\n",
      "                dict(prob=0.5, type='RandomFlip'),\r\n",
      "                dict(type='PackDetInputs'),\r\n",
      "            ],\r\n",
      "            type='CocoDataset'),\r\n",
      "        times=3,\r\n",
      "        type='RepeatDataset'),\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(\r\n",
      "        keep_ratio=True,\r\n",
      "        scale=[\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                640,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ),\r\n",
      "        ],\r\n",
      "        type='RandomResize'),\r\n",
      "    dict(prob=0.5, type='RandomFlip'),\r\n",
      "    dict(type='PackDetInputs'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "val_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    name='visualizer',\r\n",
      "    type='DetLocalVisualizer',\r\n",
      "    vis_backends=[\r\n",
      "        dict(type='LocalVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = './work_dirs/faster-rcnn_x101-64x4d_fpn_ms-3x_coco'\r\n",
      "\r\n",
      "05/10 23:19:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "05/10 23:19:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.57s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.41s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Loads checkpoint by local backend from path: checkpoints/faster_rcnn_x101_64x4d_fpn_mstrain_3x.pth\r\n",
      "05/10 23:19:43 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Load checkpoint from checkpoints/faster_rcnn_x101_64x4d_fpn_mstrain_3x.pth\r\n",
      "05/10 23:19:49 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [  50/5000]    eta: 0:10:06  time: 0.1226  data_time: 0.0031  memory: 747  \r\n",
      "05/10 23:19:55 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 100/5000]    eta: 0:09:19  time: 0.1059  data_time: 0.0021  memory: 738  \r\n",
      "05/10 23:20:00 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 150/5000]    eta: 0:09:01  time: 0.1065  data_time: 0.0020  memory: 747  \r\n",
      "05/10 23:20:05 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 200/5000]    eta: 0:08:44  time: 0.1023  data_time: 0.0022  memory: 733  \r\n",
      "05/10 23:20:10 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 250/5000]    eta: 0:08:34  time: 0.1044  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:20:16 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 300/5000]    eta: 0:08:27  time: 0.1058  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:20:21 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 350/5000]    eta: 0:08:15  time: 0.0978  data_time: 0.0019  memory: 731  \r\n",
      "05/10 23:20:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 400/5000]    eta: 0:08:06  time: 0.1009  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:20:31 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 450/5000]    eta: 0:08:03  time: 0.1104  data_time: 0.0017  memory: 731  \r\n",
      "05/10 23:20:36 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 500/5000]    eta: 0:07:56  time: 0.1012  data_time: 0.0017  memory: 738  \r\n",
      "05/10 23:20:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 550/5000]    eta: 0:07:50  time: 0.1046  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:20:47 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 600/5000]    eta: 0:07:44  time: 0.1049  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:20:52 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 650/5000]    eta: 0:07:38  time: 0.1041  data_time: 0.0018  memory: 733  \r\n",
      "05/10 23:20:57 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 700/5000]    eta: 0:07:33  time: 0.1066  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:21:02 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 750/5000]    eta: 0:07:28  time: 0.1066  data_time: 0.0019  memory: 733  \r\n",
      "05/10 23:21:08 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 800/5000]    eta: 0:07:22  time: 0.1019  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:21:13 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 850/5000]    eta: 0:07:16  time: 0.1033  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:21:18 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 900/5000]    eta: 0:07:10  time: 0.1007  data_time: 0.0021  memory: 733  \r\n",
      "05/10 23:21:23 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 950/5000]    eta: 0:07:05  time: 0.1050  data_time: 0.0018  memory: 731  \r\n",
      "05/10 23:21:29 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1000/5000]    eta: 0:07:01  time: 0.1120  data_time: 0.0019  memory: 733  \r\n",
      "05/10 23:21:34 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1050/5000]    eta: 0:06:56  time: 0.1051  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:21:39 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1100/5000]    eta: 0:06:51  time: 0.1060  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:21:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1150/5000]    eta: 0:06:48  time: 0.1214  data_time: 0.0021  memory: 731  \r\n",
      "05/10 23:21:51 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1200/5000]    eta: 0:06:45  time: 0.1182  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:21:56 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1250/5000]    eta: 0:06:38  time: 0.1014  data_time: 0.0018  memory: 733  \r\n",
      "05/10 23:22:01 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1300/5000]    eta: 0:06:32  time: 0.1015  data_time: 0.0017  memory: 747  \r\n",
      "05/10 23:22:07 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1350/5000]    eta: 0:06:29  time: 0.1169  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:22:12 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1400/5000]    eta: 0:06:22  time: 0.1003  data_time: 0.0019  memory: 738  \r\n",
      "05/10 23:22:18 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1450/5000]    eta: 0:06:18  time: 0.1096  data_time: 0.0023  memory: 747  \r\n",
      "05/10 23:22:23 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1500/5000]    eta: 0:06:12  time: 0.1085  data_time: 0.0020  memory: 731  \r\n",
      "05/10 23:22:28 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1550/5000]    eta: 0:06:07  time: 0.1056  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:22:34 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1600/5000]    eta: 0:06:01  time: 0.1023  data_time: 0.0017  memory: 738  \r\n",
      "05/10 23:22:39 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1650/5000]    eta: 0:05:55  time: 0.1005  data_time: 0.0017  memory: 747  \r\n",
      "05/10 23:22:44 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1700/5000]    eta: 0:05:50  time: 0.1037  data_time: 0.0017  memory: 733  \r\n",
      "05/10 23:22:49 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1750/5000]    eta: 0:05:45  time: 0.1067  data_time: 0.0020  memory: 747  \r\n",
      "05/10 23:22:54 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1800/5000]    eta: 0:05:39  time: 0.1063  data_time: 0.0019  memory: 733  \r\n",
      "05/10 23:23:00 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1850/5000]    eta: 0:05:34  time: 0.1055  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:23:05 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1900/5000]    eta: 0:05:29  time: 0.1090  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:23:10 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1950/5000]    eta: 0:05:23  time: 0.1058  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:23:16 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2000/5000]    eta: 0:05:18  time: 0.1082  data_time: 0.0021  memory: 747  \r\n",
      "05/10 23:23:21 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2050/5000]    eta: 0:05:13  time: 0.1029  data_time: 0.0018  memory: 725  \r\n",
      "05/10 23:23:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2100/5000]    eta: 0:05:07  time: 0.1010  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:23:31 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2150/5000]    eta: 0:05:02  time: 0.1044  data_time: 0.0018  memory: 733  \r\n",
      "05/10 23:23:37 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2200/5000]    eta: 0:04:57  time: 0.1121  data_time: 0.0020  memory: 733  \r\n",
      "05/10 23:23:42 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2250/5000]    eta: 0:04:51  time: 0.1063  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:23:47 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2300/5000]    eta: 0:04:46  time: 0.1043  data_time: 0.0019  memory: 714  \r\n",
      "05/10 23:23:53 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2350/5000]    eta: 0:04:41  time: 0.1147  data_time: 0.0018  memory: 733  \r\n",
      "05/10 23:23:58 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2400/5000]    eta: 0:04:36  time: 0.1051  data_time: 0.0023  memory: 738  \r\n",
      "05/10 23:24:03 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2450/5000]    eta: 0:04:30  time: 0.1015  data_time: 0.0019  memory: 738  \r\n",
      "05/10 23:24:09 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2500/5000]    eta: 0:04:25  time: 0.1078  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:24:14 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2550/5000]    eta: 0:04:19  time: 0.1010  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:24:19 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2600/5000]    eta: 0:04:14  time: 0.1029  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:24:24 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2650/5000]    eta: 0:04:09  time: 0.1060  data_time: 0.0019  memory: 733  \r\n",
      "05/10 23:24:30 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2700/5000]    eta: 0:04:03  time: 0.1042  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:24:35 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2750/5000]    eta: 0:03:58  time: 0.1020  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:24:40 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2800/5000]    eta: 0:03:53  time: 0.1066  data_time: 0.0024  memory: 747  \r\n",
      "05/10 23:24:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2850/5000]    eta: 0:03:47  time: 0.1018  data_time: 0.0018  memory: 733  \r\n",
      "05/10 23:24:50 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2900/5000]    eta: 0:03:42  time: 0.1031  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:24:55 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2950/5000]    eta: 0:03:36  time: 0.1004  data_time: 0.0020  memory: 747  \r\n",
      "05/10 23:25:00 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3000/5000]    eta: 0:03:31  time: 0.1020  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:25:06 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3050/5000]    eta: 0:03:26  time: 0.1042  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:25:11 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3100/5000]    eta: 0:03:20  time: 0.1030  data_time: 0.0021  memory: 747  \r\n",
      "05/10 23:25:16 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3150/5000]    eta: 0:03:15  time: 0.1016  data_time: 0.0018  memory: 733  \r\n",
      "05/10 23:25:21 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3200/5000]    eta: 0:03:10  time: 0.1095  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:25:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3250/5000]    eta: 0:03:04  time: 0.1028  data_time: 0.0018  memory: 714  \r\n",
      "05/10 23:25:31 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3300/5000]    eta: 0:02:59  time: 0.1004  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:25:36 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3350/5000]    eta: 0:02:53  time: 0.0994  data_time: 0.0020  memory: 747  \r\n",
      "05/10 23:25:42 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3400/5000]    eta: 0:02:48  time: 0.1017  data_time: 0.0018  memory: 733  \r\n",
      "05/10 23:25:47 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3450/5000]    eta: 0:02:43  time: 0.1033  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:25:52 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3500/5000]    eta: 0:02:37  time: 0.0983  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:25:57 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3550/5000]    eta: 0:02:32  time: 0.0989  data_time: 0.0023  memory: 738  \r\n",
      "05/10 23:26:02 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3600/5000]    eta: 0:02:27  time: 0.1003  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:26:07 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3650/5000]    eta: 0:02:21  time: 0.0999  data_time: 0.0020  memory: 747  \r\n",
      "05/10 23:26:12 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3700/5000]    eta: 0:02:16  time: 0.0997  data_time: 0.0018  memory: 714  \r\n",
      "05/10 23:26:17 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3750/5000]    eta: 0:02:11  time: 0.1018  data_time: 0.0021  memory: 733  \r\n",
      "05/10 23:26:22 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3800/5000]    eta: 0:02:06  time: 0.1165  data_time: 0.0017  memory: 738  \r\n",
      "05/10 23:26:28 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3850/5000]    eta: 0:02:00  time: 0.1076  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:26:34 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3900/5000]    eta: 0:01:55  time: 0.1210  data_time: 0.0018  memory: 733  \r\n",
      "05/10 23:26:40 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3950/5000]    eta: 0:01:50  time: 0.1245  data_time: 0.0019  memory: 731  \r\n",
      "05/10 23:26:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4000/5000]    eta: 0:01:45  time: 0.0972  data_time: 0.0019  memory: 725  \r\n",
      "05/10 23:26:51 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4050/5000]    eta: 0:01:40  time: 0.1174  data_time: 0.0021  memory: 738  \r\n",
      "05/10 23:26:56 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4100/5000]    eta: 0:01:34  time: 0.1051  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:27:02 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4150/5000]    eta: 0:01:29  time: 0.1115  data_time: 0.0018  memory: 725  \r\n",
      "05/10 23:27:07 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4200/5000]    eta: 0:01:24  time: 0.0982  data_time: 0.0018  memory: 731  \r\n",
      "05/10 23:27:11 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4250/5000]    eta: 0:01:19  time: 0.0959  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:27:16 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4300/5000]    eta: 0:01:13  time: 0.0990  data_time: 0.0024  memory: 731  \r\n",
      "05/10 23:27:21 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4350/5000]    eta: 0:01:08  time: 0.0980  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:27:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4400/5000]    eta: 0:01:03  time: 0.1019  data_time: 0.0020  memory: 733  \r\n",
      "05/10 23:27:31 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4450/5000]    eta: 0:00:57  time: 0.0961  data_time: 0.0018  memory: 733  \r\n",
      "05/10 23:27:36 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4500/5000]    eta: 0:00:52  time: 0.0981  data_time: 0.0017  memory: 738  \r\n",
      "05/10 23:27:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4550/5000]    eta: 0:00:47  time: 0.1031  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:27:46 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4600/5000]    eta: 0:00:41  time: 0.1025  data_time: 0.0021  memory: 733  \r\n",
      "05/10 23:27:51 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4650/5000]    eta: 0:00:36  time: 0.1010  data_time: 0.0022  memory: 714  \r\n",
      "05/10 23:27:56 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4700/5000]    eta: 0:00:31  time: 0.1014  data_time: 0.0019  memory: 738  \r\n",
      "05/10 23:28:01 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4750/5000]    eta: 0:00:26  time: 0.0973  data_time: 0.0018  memory: 733  \r\n",
      "05/10 23:28:06 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4800/5000]    eta: 0:00:20  time: 0.0991  data_time: 0.0020  memory: 747  \r\n",
      "05/10 23:28:11 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4850/5000]    eta: 0:00:15  time: 0.0985  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:28:16 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4900/5000]    eta: 0:00:10  time: 0.0995  data_time: 0.0021  memory: 738  \r\n",
      "05/10 23:28:21 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4950/5000]    eta: 0:00:05  time: 0.1003  data_time: 0.0022  memory: 747  \r\n",
      "05/10 23:28:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [5000/5000]    eta: 0:00:00  time: 0.0983  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:28:27 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.32s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=14.75s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=2.39s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.636\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.473\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.265\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.469\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.561\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.558\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.558\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.558\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.368\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.593\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.703\r\n",
      "05/10 23:28:46 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - bbox_mAP_copypaste: 0.431 0.636 0.473 0.265 0.469 0.561\r\n",
      "05/10 23:28:46 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [5000/5000]    coco/bbox_mAP: 0.4310  coco/bbox_mAP_50: 0.6360  coco/bbox_mAP_75: 0.4730  coco/bbox_mAP_s: 0.2650  coco/bbox_mAP_m: 0.4690  coco/bbox_mAP_l: 0.5610  data_time: 0.0019  time: 0.1045\r\n"
     ]
    }
   ],
   "execution_count": 3,
   "source": "!python tools/test.py configs/faster_rcnn/faster-rcnn_x101-64x4d_fpn_ms-3x_coco.py checkpoints/faster_rcnn_x101_64x4d_fpn_mstrain_3x.pth #--out result_yolox #--show",
   "id": "3c89e697d893587"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DETR",
   "id": "2dd4e11baa5e89e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/10 23:19:40 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.11.9 (main, Apr 17 2024, 00:00:00) [GCC 13.2.1 20240316 (Red Hat 13.2.1-7)]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 1907556048\r\n",
      "    GPU 0: NVIDIA GeForce RTX 3070\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.131\r\n",
      "    GCC: gcc (GCC) 13.2.1 20240316 (Red Hat 13.2.1-7)\r\n",
      "    PyTorch: 2.1.0+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 8.9.2\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.16.0+cu121\r\n",
      "    OpenCV: 4.9.0\r\n",
      "    MMEngine: 0.10.4\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 1907556048\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "05/10 23:19:40 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\r\n",
      "backend_args = None\r\n",
      "data_root = 'data/coco/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\r\n",
      "    logger=dict(interval=50, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(type='DetVisualizationHook'))\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "launcher = 'none'\r\n",
      "load_from = 'checkpoints/faster_rcnn_x101_64x4d_fpn_mstrain_3x.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        base_width=4,\r\n",
      "        depth=101,\r\n",
      "        frozen_stages=1,\r\n",
      "        groups=64,\r\n",
      "        init_cfg=dict(\r\n",
      "            checkpoint='open-mmlab://resnext101_64x4d', type='Pretrained'),\r\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\r\n",
      "        norm_eval=True,\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(\r\n",
      "            0,\r\n",
      "            1,\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "        ),\r\n",
      "        style='pytorch',\r\n",
      "        type='ResNeXt'),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        bgr_to_rgb=True,\r\n",
      "        mean=[\r\n",
      "            123.675,\r\n",
      "            116.28,\r\n",
      "            103.53,\r\n",
      "        ],\r\n",
      "        pad_size_divisor=32,\r\n",
      "        std=[\r\n",
      "            58.395,\r\n",
      "            57.12,\r\n",
      "            57.375,\r\n",
      "        ],\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        in_channels=[\r\n",
      "            256,\r\n",
      "            512,\r\n",
      "            1024,\r\n",
      "            2048,\r\n",
      "        ],\r\n",
      "        num_outs=5,\r\n",
      "        out_channels=256,\r\n",
      "        type='FPN'),\r\n",
      "    roi_head=dict(\r\n",
      "        bbox_head=dict(\r\n",
      "            bbox_coder=dict(\r\n",
      "                target_means=[\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                    0.0,\r\n",
      "                ],\r\n",
      "                target_stds=[\r\n",
      "                    0.1,\r\n",
      "                    0.1,\r\n",
      "                    0.2,\r\n",
      "                    0.2,\r\n",
      "                ],\r\n",
      "                type='DeltaXYWHBBoxCoder'),\r\n",
      "            fc_out_channels=1024,\r\n",
      "            in_channels=256,\r\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "            loss_cls=dict(\r\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\r\n",
      "            num_classes=80,\r\n",
      "            reg_class_agnostic=False,\r\n",
      "            roi_feat_size=7,\r\n",
      "            type='Shared2FCBBoxHead'),\r\n",
      "        bbox_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        type='StandardRoIHead'),\r\n",
      "    rpn_head=dict(\r\n",
      "        anchor_generator=dict(\r\n",
      "            ratios=[\r\n",
      "                0.5,\r\n",
      "                1.0,\r\n",
      "                2.0,\r\n",
      "            ],\r\n",
      "            scales=[\r\n",
      "                8,\r\n",
      "            ],\r\n",
      "            strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "                64,\r\n",
      "            ],\r\n",
      "            type='AnchorGenerator'),\r\n",
      "        bbox_coder=dict(\r\n",
      "            target_means=[\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "            ],\r\n",
      "            target_stds=[\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "            ],\r\n",
      "            type='DeltaXYWHBBoxCoder'),\r\n",
      "        feat_channels=256,\r\n",
      "        in_channels=256,\r\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\r\n",
      "        type='RPNHead'),\r\n",
      "    test_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            max_per_img=100,\r\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\r\n",
      "            score_thr=0.05),\r\n",
      "        rpn=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=1000)),\r\n",
      "    train_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=False,\r\n",
      "                min_pos_iou=0.5,\r\n",
      "                neg_iou_thr=0.5,\r\n",
      "                pos_iou_thr=0.5,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=True,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=512,\r\n",
      "                pos_fraction=0.25,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn=dict(\r\n",
      "            allowed_border=-1,\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                match_low_quality=True,\r\n",
      "                min_pos_iou=0.3,\r\n",
      "                neg_iou_thr=0.3,\r\n",
      "                pos_iou_thr=0.7,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=False,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=256,\r\n",
      "                pos_fraction=0.5,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn_proposal=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=2000)),\r\n",
      "    type='FasterRCNN')\r\n",
      "optim_wrapper = dict(\r\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0001),\r\n",
      "    type='OptimWrapper')\r\n",
      "param_scheduler = [\r\n",
      "    dict(\r\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\r\n",
      "    dict(\r\n",
      "        begin=0,\r\n",
      "        by_epoch=True,\r\n",
      "        end=12,\r\n",
      "        gamma=0.1,\r\n",
      "        milestones=[\r\n",
      "            9,\r\n",
      "            11,\r\n",
      "        ],\r\n",
      "        type='MultiStepLR'),\r\n",
      "]\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        1333,\r\n",
      "        800,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=12, type='EpochBasedTrainLoop', val_interval=1)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\r\n",
      "    batch_size=2,\r\n",
      "    dataset=dict(\r\n",
      "        dataset=dict(\r\n",
      "            ann_file='annotations/instances_train2017.json',\r\n",
      "            backend_args=None,\r\n",
      "            data_prefix=dict(img='train2017/'),\r\n",
      "            data_root='data/coco/',\r\n",
      "            filter_cfg=dict(filter_empty_gt=True, min_size=32),\r\n",
      "            pipeline=[\r\n",
      "                dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "                dict(\r\n",
      "                    keep_ratio=True,\r\n",
      "                    scale=[\r\n",
      "                        (\r\n",
      "                            1333,\r\n",
      "                            640,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            1333,\r\n",
      "                            800,\r\n",
      "                        ),\r\n",
      "                    ],\r\n",
      "                    type='RandomResize'),\r\n",
      "                dict(prob=0.5, type='RandomFlip'),\r\n",
      "                dict(type='PackDetInputs'),\r\n",
      "            ],\r\n",
      "            type='CocoDataset'),\r\n",
      "        times=3,\r\n",
      "        type='RepeatDataset'),\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(\r\n",
      "        keep_ratio=True,\r\n",
      "        scale=[\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                640,\r\n",
      "            ),\r\n",
      "            (\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ),\r\n",
      "        ],\r\n",
      "        type='RandomResize'),\r\n",
      "    dict(prob=0.5, type='RandomFlip'),\r\n",
      "    dict(type='PackDetInputs'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "val_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    name='visualizer',\r\n",
      "    type='DetLocalVisualizer',\r\n",
      "    vis_backends=[\r\n",
      "        dict(type='LocalVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = './work_dirs/faster-rcnn_x101-64x4d_fpn_ms-3x_coco'\r\n",
      "\r\n",
      "05/10 23:19:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "05/10 23:19:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.57s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.41s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Loads checkpoint by local backend from path: checkpoints/faster_rcnn_x101_64x4d_fpn_mstrain_3x.pth\r\n",
      "05/10 23:19:43 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Load checkpoint from checkpoints/faster_rcnn_x101_64x4d_fpn_mstrain_3x.pth\r\n",
      "05/10 23:19:49 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [  50/5000]    eta: 0:10:06  time: 0.1226  data_time: 0.0031  memory: 747  \r\n",
      "05/10 23:19:55 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 100/5000]    eta: 0:09:19  time: 0.1059  data_time: 0.0021  memory: 738  \r\n",
      "05/10 23:20:00 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 150/5000]    eta: 0:09:01  time: 0.1065  data_time: 0.0020  memory: 747  \r\n",
      "05/10 23:20:05 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 200/5000]    eta: 0:08:44  time: 0.1023  data_time: 0.0022  memory: 733  \r\n",
      "05/10 23:20:10 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 250/5000]    eta: 0:08:34  time: 0.1044  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:20:16 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 300/5000]    eta: 0:08:27  time: 0.1058  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:20:21 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 350/5000]    eta: 0:08:15  time: 0.0978  data_time: 0.0019  memory: 731  \r\n",
      "05/10 23:20:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 400/5000]    eta: 0:08:06  time: 0.1009  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:20:31 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 450/5000]    eta: 0:08:03  time: 0.1104  data_time: 0.0017  memory: 731  \r\n",
      "05/10 23:20:36 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 500/5000]    eta: 0:07:56  time: 0.1012  data_time: 0.0017  memory: 738  \r\n",
      "05/10 23:20:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 550/5000]    eta: 0:07:50  time: 0.1046  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:20:47 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 600/5000]    eta: 0:07:44  time: 0.1049  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:20:52 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 650/5000]    eta: 0:07:38  time: 0.1041  data_time: 0.0018  memory: 733  \r\n",
      "05/10 23:20:57 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 700/5000]    eta: 0:07:33  time: 0.1066  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:21:02 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 750/5000]    eta: 0:07:28  time: 0.1066  data_time: 0.0019  memory: 733  \r\n",
      "05/10 23:21:08 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 800/5000]    eta: 0:07:22  time: 0.1019  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:21:13 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 850/5000]    eta: 0:07:16  time: 0.1033  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:21:18 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 900/5000]    eta: 0:07:10  time: 0.1007  data_time: 0.0021  memory: 733  \r\n",
      "05/10 23:21:23 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 950/5000]    eta: 0:07:05  time: 0.1050  data_time: 0.0018  memory: 731  \r\n",
      "05/10 23:21:29 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1000/5000]    eta: 0:07:01  time: 0.1120  data_time: 0.0019  memory: 733  \r\n",
      "05/10 23:21:34 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1050/5000]    eta: 0:06:56  time: 0.1051  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:21:39 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1100/5000]    eta: 0:06:51  time: 0.1060  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:21:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1150/5000]    eta: 0:06:48  time: 0.1214  data_time: 0.0021  memory: 731  \r\n",
      "05/10 23:21:51 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1200/5000]    eta: 0:06:45  time: 0.1182  data_time: 0.0018  memory: 747  \r\n",
      "05/10 23:21:56 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1250/5000]    eta: 0:06:38  time: 0.1014  data_time: 0.0018  memory: 733  \r\n",
      "05/10 23:22:01 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1300/5000]    eta: 0:06:32  time: 0.1015  data_time: 0.0017  memory: 747  \r\n",
      "05/10 23:22:07 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1350/5000]    eta: 0:06:29  time: 0.1169  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:22:12 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1400/5000]    eta: 0:06:22  time: 0.1003  data_time: 0.0019  memory: 738  \r\n",
      "05/10 23:22:18 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1450/5000]    eta: 0:06:18  time: 0.1096  data_time: 0.0023  memory: 747  \r\n",
      "05/10 23:22:23 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1500/5000]    eta: 0:06:12  time: 0.1085  data_time: 0.0020  memory: 731  \r\n",
      "05/10 23:22:28 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1550/5000]    eta: 0:06:07  time: 0.1056  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:22:34 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1600/5000]    eta: 0:06:01  time: 0.1023  data_time: 0.0017  memory: 738  \r\n",
      "05/10 23:22:39 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1650/5000]    eta: 0:05:55  time: 0.1005  data_time: 0.0017  memory: 747  \r\n",
      "05/10 23:22:44 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1700/5000]    eta: 0:05:50  time: 0.1037  data_time: 0.0017  memory: 733  \r\n",
      "05/10 23:22:49 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1750/5000]    eta: 0:05:45  time: 0.1067  data_time: 0.0020  memory: 747  \r\n",
      "05/10 23:22:54 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1800/5000]    eta: 0:05:39  time: 0.1063  data_time: 0.0019  memory: 733  \r\n",
      "05/10 23:23:00 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1850/5000]    eta: 0:05:34  time: 0.1055  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:23:05 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1900/5000]    eta: 0:05:29  time: 0.1090  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:23:10 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1950/5000]    eta: 0:05:23  time: 0.1058  data_time: 0.0019  memory: 747  \r\n",
      "05/10 23:23:16 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2000/5000]    eta: 0:05:18  time: 0.1082  data_time: 0.0021  memory: 747  \r\n",
      "05/10 23:23:21 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2050/5000]    eta: 0:05:13  time: 0.1029  data_time: 0.0018  memory: 725  \r\n",
      "05/10 23:23:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2100/5000]    eta: 0:05:07  time: 0.1010  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:23:31 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2150/5000]    eta: 0:05:02  time: 0.1044  data_time: 0.0018  memory: 733  \r\n",
      "05/10 23:23:37 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2200/5000]    eta: 0:04:57  time: 0.1121  data_time: 0.0020  memory: 733  \r\n",
      "05/10 23:23:42 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2250/5000]    eta: 0:04:51  time: 0.1063  data_time: 0.0018  memory: 738  \r\n",
      "05/10 23:23:47 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2300/5000]    eta: 0:04:46  time: 0.1043  data_time: 0.0019  memory: 714  \r\n"
     ]
    }
   ],
   "execution_count": null,
   "source": "!python tools/test.py configs/detr/detr_r101_8xb2-500e_coco.py checkpoints/detr.pth #--out result_yolox #--show",
   "id": "59bf33a4ae4a3922"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# YOLOX",
   "id": "fa0e60dffe337e58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/10 22:34:10 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.11.9 (main, Apr 17 2024, 00:00:00) [GCC 13.2.1 20240316 (Red Hat 13.2.1-7)]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 1655412138\r\n",
      "    GPU 0: NVIDIA GeForce RTX 3070\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.131\r\n",
      "    GCC: gcc (GCC) 13.2.1 20240316 (Red Hat 13.2.1-7)\r\n",
      "    PyTorch: 2.1.0+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 8.9.2\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.16.0+cu121\r\n",
      "    OpenCV: 4.9.0\r\n",
      "    MMEngine: 0.10.4\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 1655412138\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "05/10 22:34:10 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=64, enable=False)\r\n",
      "backend_args = None\r\n",
      "base_lr = 0.01\r\n",
      "custom_hooks = [\r\n",
      "    dict(num_last_epochs=15, priority=48, type='YOLOXModeSwitchHook'),\r\n",
      "    dict(priority=48, type='SyncNormHook'),\r\n",
      "    dict(\r\n",
      "        ema_type='ExpMomentumEMA',\r\n",
      "        momentum=0.0001,\r\n",
      "        priority=49,\r\n",
      "        type='EMAHook',\r\n",
      "        update_buffers=True),\r\n",
      "]\r\n",
      "data_root = 'data/coco/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(interval=10, max_keep_ckpts=3, type='CheckpointHook'),\r\n",
      "    logger=dict(interval=50, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(type='DetVisualizationHook'))\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "img_scale = (\r\n",
      "    640,\r\n",
      "    640,\r\n",
      ")\r\n",
      "img_scales = [\r\n",
      "    (\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ),\r\n",
      "    (\r\n",
      "        320,\r\n",
      "        320,\r\n",
      "    ),\r\n",
      "    (\r\n",
      "        960,\r\n",
      "        960,\r\n",
      "    ),\r\n",
      "]\r\n",
      "interval = 10\r\n",
      "launcher = 'none'\r\n",
      "load_from = 'checkpoints/yolox_s.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\r\n",
      "max_epochs = 300\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        act_cfg=dict(type='Swish'),\r\n",
      "        deepen_factor=0.33,\r\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\r\n",
      "        out_indices=(\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "            4,\r\n",
      "        ),\r\n",
      "        spp_kernal_sizes=(\r\n",
      "            5,\r\n",
      "            9,\r\n",
      "            13,\r\n",
      "        ),\r\n",
      "        type='CSPDarknet',\r\n",
      "        use_depthwise=False,\r\n",
      "        widen_factor=0.5),\r\n",
      "    bbox_head=dict(\r\n",
      "        act_cfg=dict(type='Swish'),\r\n",
      "        feat_channels=128,\r\n",
      "        in_channels=128,\r\n",
      "        loss_bbox=dict(\r\n",
      "            eps=1e-16,\r\n",
      "            loss_weight=5.0,\r\n",
      "            mode='square',\r\n",
      "            reduction='sum',\r\n",
      "            type='IoULoss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0,\r\n",
      "            reduction='sum',\r\n",
      "            type='CrossEntropyLoss',\r\n",
      "            use_sigmoid=True),\r\n",
      "        loss_l1=dict(loss_weight=1.0, reduction='sum', type='L1Loss'),\r\n",
      "        loss_obj=dict(\r\n",
      "            loss_weight=1.0,\r\n",
      "            reduction='sum',\r\n",
      "            type='CrossEntropyLoss',\r\n",
      "            use_sigmoid=True),\r\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\r\n",
      "        num_classes=80,\r\n",
      "        stacked_convs=2,\r\n",
      "        strides=(\r\n",
      "            8,\r\n",
      "            16,\r\n",
      "            32,\r\n",
      "        ),\r\n",
      "        type='YOLOXHead',\r\n",
      "        use_depthwise=False),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        batch_augments=[\r\n",
      "            dict(\r\n",
      "                interval=10,\r\n",
      "                random_size_range=(\r\n",
      "                    480,\r\n",
      "                    800,\r\n",
      "                ),\r\n",
      "                size_divisor=32,\r\n",
      "                type='BatchSyncRandomResize'),\r\n",
      "        ],\r\n",
      "        pad_size_divisor=32,\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        act_cfg=dict(type='Swish'),\r\n",
      "        in_channels=[\r\n",
      "            128,\r\n",
      "            256,\r\n",
      "            512,\r\n",
      "        ],\r\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\r\n",
      "        num_csp_blocks=1,\r\n",
      "        out_channels=128,\r\n",
      "        type='YOLOXPAFPN',\r\n",
      "        upsample_cfg=dict(mode='nearest', scale_factor=2),\r\n",
      "        use_depthwise=False),\r\n",
      "    test_cfg=dict(nms=dict(iou_threshold=0.65, type='nms'), score_thr=0.01),\r\n",
      "    train_cfg=dict(assigner=dict(center_radius=2.5, type='SimOTAAssigner')),\r\n",
      "    type='YOLOX')\r\n",
      "num_last_epochs = 15\r\n",
      "optim_wrapper = dict(\r\n",
      "    optimizer=dict(\r\n",
      "        lr=0.01, momentum=0.9, nesterov=True, type='SGD', weight_decay=0.0005),\r\n",
      "    paramwise_cfg=dict(bias_decay_mult=0.0, norm_decay_mult=0.0),\r\n",
      "    type='OptimWrapper')\r\n",
      "param_scheduler = [\r\n",
      "    dict(\r\n",
      "        begin=0,\r\n",
      "        by_epoch=True,\r\n",
      "        convert_to_iter_based=True,\r\n",
      "        end=5,\r\n",
      "        type='mmdet.QuadraticWarmupLR'),\r\n",
      "    dict(\r\n",
      "        T_max=285,\r\n",
      "        begin=5,\r\n",
      "        by_epoch=True,\r\n",
      "        convert_to_iter_based=True,\r\n",
      "        end=285,\r\n",
      "        eta_min=0.0005,\r\n",
      "        type='CosineAnnealingLR'),\r\n",
      "    dict(begin=285, by_epoch=True, end=300, factor=1, type='ConstantLR'),\r\n",
      "]\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=8,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(\r\n",
      "                pad_to_square=True,\r\n",
      "                pad_val=dict(img=(\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                )),\r\n",
      "                type='Pad'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=4,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(\r\n",
      "        pad_to_square=True,\r\n",
      "        pad_val=dict(img=(\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "        )),\r\n",
      "        type='Pad'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=300, type='EpochBasedTrainLoop', val_interval=10)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_size=8,\r\n",
      "    dataset=dict(\r\n",
      "        dataset=dict(\r\n",
      "            ann_file='annotations/instances_train2017.json',\r\n",
      "            backend_args=None,\r\n",
      "            data_prefix=dict(img='train2017/'),\r\n",
      "            data_root='data/coco/',\r\n",
      "            filter_cfg=dict(filter_empty_gt=False, min_size=32),\r\n",
      "            pipeline=[\r\n",
      "                dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            ],\r\n",
      "            type='CocoDataset'),\r\n",
      "        pipeline=[\r\n",
      "            dict(img_scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), pad_val=114.0, type='Mosaic'),\r\n",
      "            dict(\r\n",
      "                border=(\r\n",
      "                    -320,\r\n",
      "                    -320,\r\n",
      "                ),\r\n",
      "                scaling_ratio_range=(\r\n",
      "                    0.1,\r\n",
      "                    2,\r\n",
      "                ),\r\n",
      "                type='RandomAffine'),\r\n",
      "            dict(\r\n",
      "                img_scale=(\r\n",
      "                    640,\r\n",
      "                    640,\r\n",
      "                ),\r\n",
      "                pad_val=114.0,\r\n",
      "                ratio_range=(\r\n",
      "                    0.8,\r\n",
      "                    1.6,\r\n",
      "                ),\r\n",
      "                type='MixUp'),\r\n",
      "            dict(type='YOLOXHSVRandomAug'),\r\n",
      "            dict(prob=0.5, type='RandomFlip'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(\r\n",
      "                pad_to_square=True,\r\n",
      "                pad_val=dict(img=(\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                )),\r\n",
      "                type='Pad'),\r\n",
      "            dict(\r\n",
      "                keep_empty=False,\r\n",
      "                min_gt_bbox_wh=(\r\n",
      "                    1,\r\n",
      "                    1,\r\n",
      "                ),\r\n",
      "                type='FilterAnnotations'),\r\n",
      "            dict(type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        type='MultiImageMixDataset'),\r\n",
      "    num_workers=4,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_dataset = dict(\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_train2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='train2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "        ],\r\n",
      "        type='CocoDataset'),\r\n",
      "    pipeline=[\r\n",
      "        dict(img_scale=(\r\n",
      "            640,\r\n",
      "            640,\r\n",
      "        ), pad_val=114.0, type='Mosaic'),\r\n",
      "        dict(\r\n",
      "            border=(\r\n",
      "                -320,\r\n",
      "                -320,\r\n",
      "            ),\r\n",
      "            scaling_ratio_range=(\r\n",
      "                0.1,\r\n",
      "                2,\r\n",
      "            ),\r\n",
      "            type='RandomAffine'),\r\n",
      "        dict(\r\n",
      "            img_scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ),\r\n",
      "            pad_val=114.0,\r\n",
      "            ratio_range=(\r\n",
      "                0.8,\r\n",
      "                1.6,\r\n",
      "            ),\r\n",
      "            type='MixUp'),\r\n",
      "        dict(type='YOLOXHSVRandomAug'),\r\n",
      "        dict(prob=0.5, type='RandomFlip'),\r\n",
      "        dict(keep_ratio=True, scale=(\r\n",
      "            640,\r\n",
      "            640,\r\n",
      "        ), type='Resize'),\r\n",
      "        dict(\r\n",
      "            pad_to_square=True,\r\n",
      "            pad_val=dict(img=(\r\n",
      "                114.0,\r\n",
      "                114.0,\r\n",
      "                114.0,\r\n",
      "            )),\r\n",
      "            type='Pad'),\r\n",
      "        dict(\r\n",
      "            keep_empty=False,\r\n",
      "            min_gt_bbox_wh=(\r\n",
      "                1,\r\n",
      "                1,\r\n",
      "            ),\r\n",
      "            type='FilterAnnotations'),\r\n",
      "        dict(type='PackDetInputs'),\r\n",
      "    ],\r\n",
      "    type='MultiImageMixDataset')\r\n",
      "train_pipeline = [\r\n",
      "    dict(img_scale=(\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ), pad_val=114.0, type='Mosaic'),\r\n",
      "    dict(\r\n",
      "        border=(\r\n",
      "            -320,\r\n",
      "            -320,\r\n",
      "        ),\r\n",
      "        scaling_ratio_range=(\r\n",
      "            0.1,\r\n",
      "            2,\r\n",
      "        ),\r\n",
      "        type='RandomAffine'),\r\n",
      "    dict(\r\n",
      "        img_scale=(\r\n",
      "            640,\r\n",
      "            640,\r\n",
      "        ),\r\n",
      "        pad_val=114.0,\r\n",
      "        ratio_range=(\r\n",
      "            0.8,\r\n",
      "            1.6,\r\n",
      "        ),\r\n",
      "        type='MixUp'),\r\n",
      "    dict(type='YOLOXHSVRandomAug'),\r\n",
      "    dict(prob=0.5, type='RandomFlip'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(\r\n",
      "        pad_to_square=True,\r\n",
      "        pad_val=dict(img=(\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "        )),\r\n",
      "        type='Pad'),\r\n",
      "    dict(keep_empty=False, min_gt_bbox_wh=(\r\n",
      "        1,\r\n",
      "        1,\r\n",
      "    ), type='FilterAnnotations'),\r\n",
      "    dict(type='PackDetInputs'),\r\n",
      "]\r\n",
      "tta_model = dict(\r\n",
      "    tta_cfg=dict(max_per_img=100, nms=dict(iou_threshold=0.65, type='nms')),\r\n",
      "    type='DetTTAModel')\r\n",
      "tta_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        transforms=[\r\n",
      "            [\r\n",
      "                dict(keep_ratio=True, scale=(\r\n",
      "                    640,\r\n",
      "                    640,\r\n",
      "                ), type='Resize'),\r\n",
      "                dict(keep_ratio=True, scale=(\r\n",
      "                    320,\r\n",
      "                    320,\r\n",
      "                ), type='Resize'),\r\n",
      "                dict(keep_ratio=True, scale=(\r\n",
      "                    960,\r\n",
      "                    960,\r\n",
      "                ), type='Resize'),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(prob=1.0, type='RandomFlip'),\r\n",
      "                dict(prob=0.0, type='RandomFlip'),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(\r\n",
      "                    pad_to_square=True,\r\n",
      "                    pad_val=dict(img=(\r\n",
      "                        114.0,\r\n",
      "                        114.0,\r\n",
      "                        114.0,\r\n",
      "                    )),\r\n",
      "                    type='Pad'),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(\r\n",
      "                    meta_keys=(\r\n",
      "                        'img_id',\r\n",
      "                        'img_path',\r\n",
      "                        'ori_shape',\r\n",
      "                        'img_shape',\r\n",
      "                        'scale_factor',\r\n",
      "                        'flip',\r\n",
      "                        'flip_direction',\r\n",
      "                    ),\r\n",
      "                    type='PackDetInputs'),\r\n",
      "            ],\r\n",
      "        ],\r\n",
      "        type='TestTimeAug'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=8,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(\r\n",
      "                pad_to_square=True,\r\n",
      "                pad_val=dict(img=(\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                )),\r\n",
      "                type='Pad'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=4,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "val_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    name='visualizer',\r\n",
      "    type='DetLocalVisualizer',\r\n",
      "    vis_backends=[\r\n",
      "        dict(type='LocalVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = './work_dirs/yolox_s_8xb8-300e_coco'\r\n",
      "\r\n",
      "05/10 22:34:11 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "05/10 22:34:11 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_load_checkpoint:\r\n",
      "(49          ) EMAHook                            \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(48          ) YOLOXModeSwitchHook                \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(48          ) SyncNormHook                       \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_save_checkpoint:\r\n",
      "(49          ) EMAHook                            \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.58s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.42s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Loads checkpoint by local backend from path: checkpoints/yolox_s.pth\r\n",
      "05/10 22:34:14 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Load checkpoint from checkpoints/yolox_s.pth\r\n",
      "/mnt/ntfs/SSD1/_Master6/RM/mmdetection/.venv/lib64/python3.11/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\r\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n",
      "05/10 22:34:17 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 50/625]    eta: 0:00:40  time: 0.0713  data_time: 0.0120  memory: 506  \r\n",
      "05/10 22:34:20 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [100/625]    eta: 0:00:34  time: 0.0602  data_time: 0.0085  memory: 506  \r\n",
      "05/10 22:34:23 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [150/625]    eta: 0:00:30  time: 0.0606  data_time: 0.0085  memory: 506  \r\n",
      "05/10 22:34:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [200/625]    eta: 0:00:26  time: 0.0616  data_time: 0.0091  memory: 506  \r\n",
      "05/10 22:34:29 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [250/625]    eta: 0:00:23  time: 0.0609  data_time: 0.0083  memory: 506  \r\n",
      "05/10 22:34:32 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [300/625]    eta: 0:00:20  time: 0.0626  data_time: 0.0089  memory: 506  \r\n",
      "05/10 22:34:36 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [350/625]    eta: 0:00:17  time: 0.0627  data_time: 0.0086  memory: 506  \r\n",
      "05/10 22:34:39 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [400/625]    eta: 0:00:14  time: 0.0631  data_time: 0.0089  memory: 506  \r\n",
      "05/10 22:34:42 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [450/625]    eta: 0:00:10  time: 0.0616  data_time: 0.0088  memory: 506  \r\n",
      "05/10 22:34:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [500/625]    eta: 0:00:07  time: 0.0604  data_time: 0.0083  memory: 506  \r\n",
      "05/10 22:34:48 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [550/625]    eta: 0:00:04  time: 0.0606  data_time: 0.0083  memory: 506  \r\n",
      "05/10 22:34:51 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [600/625]    eta: 0:00:01  time: 0.0613  data_time: 0.0091  memory: 506  \r\n",
      "05/10 22:34:55 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.43s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=24.49s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=3.86s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.591\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.434\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.235\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.445\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.531\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.548\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.549\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.549\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.346\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.601\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.693\r\n",
      "05/10 22:35:25 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - bbox_mAP_copypaste: 0.403 0.591 0.434 0.235 0.445 0.531\r\n",
      "05/10 22:35:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [625/625]    coco/bbox_mAP: 0.4030  coco/bbox_mAP_50: 0.5910  coco/bbox_mAP_75: 0.4340  coco/bbox_mAP_s: 0.2350  coco/bbox_mAP_m: 0.4450  coco/bbox_mAP_l: 0.5310  data_time: 0.0089  time: 0.0622\r\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": "!python tools/test.py configs/yolox/yolox_s_8xb8-300e_coco.py checkpoints/yolox_s.pth #--out result #--show",
   "id": "ec852ab7a492bc91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualize Prediction as Image",
   "id": "ffe76532c7075136"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/10 22:34:10 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.11.9 (main, Apr 17 2024, 00:00:00) [GCC 13.2.1 20240316 (Red Hat 13.2.1-7)]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 1655412138\r\n",
      "    GPU 0: NVIDIA GeForce RTX 3070\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.131\r\n",
      "    GCC: gcc (GCC) 13.2.1 20240316 (Red Hat 13.2.1-7)\r\n",
      "    PyTorch: 2.1.0+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 8.9.2\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.16.0+cu121\r\n",
      "    OpenCV: 4.9.0\r\n",
      "    MMEngine: 0.10.4\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 1655412138\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "05/10 22:34:10 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=64, enable=False)\r\n",
      "backend_args = None\r\n",
      "base_lr = 0.01\r\n",
      "custom_hooks = [\r\n",
      "    dict(num_last_epochs=15, priority=48, type='YOLOXModeSwitchHook'),\r\n",
      "    dict(priority=48, type='SyncNormHook'),\r\n",
      "    dict(\r\n",
      "        ema_type='ExpMomentumEMA',\r\n",
      "        momentum=0.0001,\r\n",
      "        priority=49,\r\n",
      "        type='EMAHook',\r\n",
      "        update_buffers=True),\r\n",
      "]\r\n",
      "data_root = 'data/coco/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(interval=10, max_keep_ckpts=3, type='CheckpointHook'),\r\n",
      "    logger=dict(interval=50, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(type='DetVisualizationHook'))\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "img_scale = (\r\n",
      "    640,\r\n",
      "    640,\r\n",
      ")\r\n",
      "img_scales = [\r\n",
      "    (\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ),\r\n",
      "    (\r\n",
      "        320,\r\n",
      "        320,\r\n",
      "    ),\r\n",
      "    (\r\n",
      "        960,\r\n",
      "        960,\r\n",
      "    ),\r\n",
      "]\r\n",
      "interval = 10\r\n",
      "launcher = 'none'\r\n",
      "load_from = 'checkpoints/yolox_s.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\r\n",
      "max_epochs = 300\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        act_cfg=dict(type='Swish'),\r\n",
      "        deepen_factor=0.33,\r\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\r\n",
      "        out_indices=(\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "            4,\r\n",
      "        ),\r\n",
      "        spp_kernal_sizes=(\r\n",
      "            5,\r\n",
      "            9,\r\n",
      "            13,\r\n",
      "        ),\r\n",
      "        type='CSPDarknet',\r\n",
      "        use_depthwise=False,\r\n",
      "        widen_factor=0.5),\r\n",
      "    bbox_head=dict(\r\n",
      "        act_cfg=dict(type='Swish'),\r\n",
      "        feat_channels=128,\r\n",
      "        in_channels=128,\r\n",
      "        loss_bbox=dict(\r\n",
      "            eps=1e-16,\r\n",
      "            loss_weight=5.0,\r\n",
      "            mode='square',\r\n",
      "            reduction='sum',\r\n",
      "            type='IoULoss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0,\r\n",
      "            reduction='sum',\r\n",
      "            type='CrossEntropyLoss',\r\n",
      "            use_sigmoid=True),\r\n",
      "        loss_l1=dict(loss_weight=1.0, reduction='sum', type='L1Loss'),\r\n",
      "        loss_obj=dict(\r\n",
      "            loss_weight=1.0,\r\n",
      "            reduction='sum',\r\n",
      "            type='CrossEntropyLoss',\r\n",
      "            use_sigmoid=True),\r\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\r\n",
      "        num_classes=80,\r\n",
      "        stacked_convs=2,\r\n",
      "        strides=(\r\n",
      "            8,\r\n",
      "            16,\r\n",
      "            32,\r\n",
      "        ),\r\n",
      "        type='YOLOXHead',\r\n",
      "        use_depthwise=False),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        batch_augments=[\r\n",
      "            dict(\r\n",
      "                interval=10,\r\n",
      "                random_size_range=(\r\n",
      "                    480,\r\n",
      "                    800,\r\n",
      "                ),\r\n",
      "                size_divisor=32,\r\n",
      "                type='BatchSyncRandomResize'),\r\n",
      "        ],\r\n",
      "        pad_size_divisor=32,\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        act_cfg=dict(type='Swish'),\r\n",
      "        in_channels=[\r\n",
      "            128,\r\n",
      "            256,\r\n",
      "            512,\r\n",
      "        ],\r\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\r\n",
      "        num_csp_blocks=1,\r\n",
      "        out_channels=128,\r\n",
      "        type='YOLOXPAFPN',\r\n",
      "        upsample_cfg=dict(mode='nearest', scale_factor=2),\r\n",
      "        use_depthwise=False),\r\n",
      "    test_cfg=dict(nms=dict(iou_threshold=0.65, type='nms'), score_thr=0.01),\r\n",
      "    train_cfg=dict(assigner=dict(center_radius=2.5, type='SimOTAAssigner')),\r\n",
      "    type='YOLOX')\r\n",
      "num_last_epochs = 15\r\n",
      "optim_wrapper = dict(\r\n",
      "    optimizer=dict(\r\n",
      "        lr=0.01, momentum=0.9, nesterov=True, type='SGD', weight_decay=0.0005),\r\n",
      "    paramwise_cfg=dict(bias_decay_mult=0.0, norm_decay_mult=0.0),\r\n",
      "    type='OptimWrapper')\r\n",
      "param_scheduler = [\r\n",
      "    dict(\r\n",
      "        begin=0,\r\n",
      "        by_epoch=True,\r\n",
      "        convert_to_iter_based=True,\r\n",
      "        end=5,\r\n",
      "        type='mmdet.QuadraticWarmupLR'),\r\n",
      "    dict(\r\n",
      "        T_max=285,\r\n",
      "        begin=5,\r\n",
      "        by_epoch=True,\r\n",
      "        convert_to_iter_based=True,\r\n",
      "        end=285,\r\n",
      "        eta_min=0.0005,\r\n",
      "        type='CosineAnnealingLR'),\r\n",
      "    dict(begin=285, by_epoch=True, end=300, factor=1, type='ConstantLR'),\r\n",
      "]\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=8,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(\r\n",
      "                pad_to_square=True,\r\n",
      "                pad_val=dict(img=(\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                )),\r\n",
      "                type='Pad'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=4,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(\r\n",
      "        pad_to_square=True,\r\n",
      "        pad_val=dict(img=(\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "        )),\r\n",
      "        type='Pad'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=300, type='EpochBasedTrainLoop', val_interval=10)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_size=8,\r\n",
      "    dataset=dict(\r\n",
      "        dataset=dict(\r\n",
      "            ann_file='annotations/instances_train2017.json',\r\n",
      "            backend_args=None,\r\n",
      "            data_prefix=dict(img='train2017/'),\r\n",
      "            data_root='data/coco/',\r\n",
      "            filter_cfg=dict(filter_empty_gt=False, min_size=32),\r\n",
      "            pipeline=[\r\n",
      "                dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            ],\r\n",
      "            type='CocoDataset'),\r\n",
      "        pipeline=[\r\n",
      "            dict(img_scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), pad_val=114.0, type='Mosaic'),\r\n",
      "            dict(\r\n",
      "                border=(\r\n",
      "                    -320,\r\n",
      "                    -320,\r\n",
      "                ),\r\n",
      "                scaling_ratio_range=(\r\n",
      "                    0.1,\r\n",
      "                    2,\r\n",
      "                ),\r\n",
      "                type='RandomAffine'),\r\n",
      "            dict(\r\n",
      "                img_scale=(\r\n",
      "                    640,\r\n",
      "                    640,\r\n",
      "                ),\r\n",
      "                pad_val=114.0,\r\n",
      "                ratio_range=(\r\n",
      "                    0.8,\r\n",
      "                    1.6,\r\n",
      "                ),\r\n",
      "                type='MixUp'),\r\n",
      "            dict(type='YOLOXHSVRandomAug'),\r\n",
      "            dict(prob=0.5, type='RandomFlip'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(\r\n",
      "                pad_to_square=True,\r\n",
      "                pad_val=dict(img=(\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                )),\r\n",
      "                type='Pad'),\r\n",
      "            dict(\r\n",
      "                keep_empty=False,\r\n",
      "                min_gt_bbox_wh=(\r\n",
      "                    1,\r\n",
      "                    1,\r\n",
      "                ),\r\n",
      "                type='FilterAnnotations'),\r\n",
      "            dict(type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        type='MultiImageMixDataset'),\r\n",
      "    num_workers=4,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_dataset = dict(\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_train2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='train2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "        ],\r\n",
      "        type='CocoDataset'),\r\n",
      "    pipeline=[\r\n",
      "        dict(img_scale=(\r\n",
      "            640,\r\n",
      "            640,\r\n",
      "        ), pad_val=114.0, type='Mosaic'),\r\n",
      "        dict(\r\n",
      "            border=(\r\n",
      "                -320,\r\n",
      "                -320,\r\n",
      "            ),\r\n",
      "            scaling_ratio_range=(\r\n",
      "                0.1,\r\n",
      "                2,\r\n",
      "            ),\r\n",
      "            type='RandomAffine'),\r\n",
      "        dict(\r\n",
      "            img_scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ),\r\n",
      "            pad_val=114.0,\r\n",
      "            ratio_range=(\r\n",
      "                0.8,\r\n",
      "                1.6,\r\n",
      "            ),\r\n",
      "            type='MixUp'),\r\n",
      "        dict(type='YOLOXHSVRandomAug'),\r\n",
      "        dict(prob=0.5, type='RandomFlip'),\r\n",
      "        dict(keep_ratio=True, scale=(\r\n",
      "            640,\r\n",
      "            640,\r\n",
      "        ), type='Resize'),\r\n",
      "        dict(\r\n",
      "            pad_to_square=True,\r\n",
      "            pad_val=dict(img=(\r\n",
      "                114.0,\r\n",
      "                114.0,\r\n",
      "                114.0,\r\n",
      "            )),\r\n",
      "            type='Pad'),\r\n",
      "        dict(\r\n",
      "            keep_empty=False,\r\n",
      "            min_gt_bbox_wh=(\r\n",
      "                1,\r\n",
      "                1,\r\n",
      "            ),\r\n",
      "            type='FilterAnnotations'),\r\n",
      "        dict(type='PackDetInputs'),\r\n",
      "    ],\r\n",
      "    type='MultiImageMixDataset')\r\n",
      "train_pipeline = [\r\n",
      "    dict(img_scale=(\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ), pad_val=114.0, type='Mosaic'),\r\n",
      "    dict(\r\n",
      "        border=(\r\n",
      "            -320,\r\n",
      "            -320,\r\n",
      "        ),\r\n",
      "        scaling_ratio_range=(\r\n",
      "            0.1,\r\n",
      "            2,\r\n",
      "        ),\r\n",
      "        type='RandomAffine'),\r\n",
      "    dict(\r\n",
      "        img_scale=(\r\n",
      "            640,\r\n",
      "            640,\r\n",
      "        ),\r\n",
      "        pad_val=114.0,\r\n",
      "        ratio_range=(\r\n",
      "            0.8,\r\n",
      "            1.6,\r\n",
      "        ),\r\n",
      "        type='MixUp'),\r\n",
      "    dict(type='YOLOXHSVRandomAug'),\r\n",
      "    dict(prob=0.5, type='RandomFlip'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(\r\n",
      "        pad_to_square=True,\r\n",
      "        pad_val=dict(img=(\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "        )),\r\n",
      "        type='Pad'),\r\n",
      "    dict(keep_empty=False, min_gt_bbox_wh=(\r\n",
      "        1,\r\n",
      "        1,\r\n",
      "    ), type='FilterAnnotations'),\r\n",
      "    dict(type='PackDetInputs'),\r\n",
      "]\r\n",
      "tta_model = dict(\r\n",
      "    tta_cfg=dict(max_per_img=100, nms=dict(iou_threshold=0.65, type='nms')),\r\n",
      "    type='DetTTAModel')\r\n",
      "tta_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        transforms=[\r\n",
      "            [\r\n",
      "                dict(keep_ratio=True, scale=(\r\n",
      "                    640,\r\n",
      "                    640,\r\n",
      "                ), type='Resize'),\r\n",
      "                dict(keep_ratio=True, scale=(\r\n",
      "                    320,\r\n",
      "                    320,\r\n",
      "                ), type='Resize'),\r\n",
      "                dict(keep_ratio=True, scale=(\r\n",
      "                    960,\r\n",
      "                    960,\r\n",
      "                ), type='Resize'),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(prob=1.0, type='RandomFlip'),\r\n",
      "                dict(prob=0.0, type='RandomFlip'),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(\r\n",
      "                    pad_to_square=True,\r\n",
      "                    pad_val=dict(img=(\r\n",
      "                        114.0,\r\n",
      "                        114.0,\r\n",
      "                        114.0,\r\n",
      "                    )),\r\n",
      "                    type='Pad'),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(\r\n",
      "                    meta_keys=(\r\n",
      "                        'img_id',\r\n",
      "                        'img_path',\r\n",
      "                        'ori_shape',\r\n",
      "                        'img_shape',\r\n",
      "                        'scale_factor',\r\n",
      "                        'flip',\r\n",
      "                        'flip_direction',\r\n",
      "                    ),\r\n",
      "                    type='PackDetInputs'),\r\n",
      "            ],\r\n",
      "        ],\r\n",
      "        type='TestTimeAug'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=8,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(\r\n",
      "                pad_to_square=True,\r\n",
      "                pad_val=dict(img=(\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                )),\r\n",
      "                type='Pad'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=4,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "val_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    name='visualizer',\r\n",
      "    type='DetLocalVisualizer',\r\n",
      "    vis_backends=[\r\n",
      "        dict(type='LocalVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = './work_dirs/yolox_s_8xb8-300e_coco'\r\n",
      "\r\n",
      "05/10 22:34:11 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "05/10 22:34:11 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_load_checkpoint:\r\n",
      "(49          ) EMAHook                            \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(48          ) YOLOXModeSwitchHook                \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(48          ) SyncNormHook                       \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_save_checkpoint:\r\n",
      "(49          ) EMAHook                            \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.58s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.42s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Loads checkpoint by local backend from path: checkpoints/yolox_s.pth\r\n",
      "05/10 22:34:14 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Load checkpoint from checkpoints/yolox_s.pth\r\n",
      "/mnt/ntfs/SSD1/_Master6/RM/mmdetection/.venv/lib64/python3.11/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\r\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n",
      "05/10 22:34:17 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 50/625]    eta: 0:00:40  time: 0.0713  data_time: 0.0120  memory: 506  \r\n",
      "05/10 22:34:20 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [100/625]    eta: 0:00:34  time: 0.0602  data_time: 0.0085  memory: 506  \r\n",
      "05/10 22:34:23 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [150/625]    eta: 0:00:30  time: 0.0606  data_time: 0.0085  memory: 506  \r\n",
      "05/10 22:34:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [200/625]    eta: 0:00:26  time: 0.0616  data_time: 0.0091  memory: 506  \r\n",
      "05/10 22:34:29 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [250/625]    eta: 0:00:23  time: 0.0609  data_time: 0.0083  memory: 506  \r\n",
      "05/10 22:34:32 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [300/625]    eta: 0:00:20  time: 0.0626  data_time: 0.0089  memory: 506  \r\n",
      "05/10 22:34:36 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [350/625]    eta: 0:00:17  time: 0.0627  data_time: 0.0086  memory: 506  \r\n",
      "05/10 22:34:39 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [400/625]    eta: 0:00:14  time: 0.0631  data_time: 0.0089  memory: 506  \r\n",
      "05/10 22:34:42 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [450/625]    eta: 0:00:10  time: 0.0616  data_time: 0.0088  memory: 506  \r\n",
      "05/10 22:34:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [500/625]    eta: 0:00:07  time: 0.0604  data_time: 0.0083  memory: 506  \r\n",
      "05/10 22:34:48 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [550/625]    eta: 0:00:04  time: 0.0606  data_time: 0.0083  memory: 506  \r\n",
      "05/10 22:34:51 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [600/625]    eta: 0:00:01  time: 0.0613  data_time: 0.0091  memory: 506  \r\n",
      "05/10 22:34:55 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.43s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=24.49s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=3.86s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.591\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.434\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.235\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.445\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.531\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.548\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.549\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.549\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.346\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.601\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.693\r\n",
      "05/10 22:35:25 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - bbox_mAP_copypaste: 0.403 0.591 0.434 0.235 0.445 0.531\r\n",
      "05/10 22:35:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [625/625]    coco/bbox_mAP: 0.4030  coco/bbox_mAP_50: 0.5910  coco/bbox_mAP_75: 0.4340  coco/bbox_mAP_s: 0.2350  coco/bbox_mAP_m: 0.4450  coco/bbox_mAP_l: 0.5310  data_time: 0.0089  time: 0.0622\r\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": "!python tools/test.py configs/yolox/yolox_s_8xb8-300e_coco.py checkpoints/yolox_s.pth --show",
   "id": "8365f20ab882ff93"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate result.pkl file (if any)",
   "id": "36ed3e7f97b00c7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\r\n",
      "Done (t=0.53s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.58s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "05/10 22:32:11 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.68s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=24.40s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=3.88s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.591\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.434\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.235\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.445\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.531\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.548\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.549\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.549\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.346\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.601\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.693\r\n",
      "05/10 22:32:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - bbox_mAP_copypaste: 0.403 0.591 0.434 0.235 0.445 0.531\r\n",
      "{'coco/bbox_mAP': 0.403, 'coco/bbox_mAP_50': 0.591, 'coco/bbox_mAP_75': 0.434, 'coco/bbox_mAP_s': 0.235, 'coco/bbox_mAP_m': 0.445, 'coco/bbox_mAP_l': 0.531}\r\n"
     ]
    }
   ],
   "execution_count": 1,
   "source": "!python tools/analysis_tools/eval_metric.py configs/yolox/yolox_s_8xb8-300e_coco.py result/result.pkl",
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
